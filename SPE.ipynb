{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Installation & Setup"
      ],
      "metadata": {
        "id": "ICkWAJgsW6yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1.1: Install Dependencies\n",
        "\n",
        "!pip install -q requests\n",
        "!pip install -q google-generativeai\n",
        "!pip install -q pandas\n",
        "!pip install -q numpy\n",
        "!pip install -q demjson3\n",
        "!pip install -q aiohttp"
      ],
      "metadata": {
        "id": "7C9mHVreJdv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52a54b7-050f-4fea-bc7b-1a9b629d0e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/131.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for demjson3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "from google.colab import userdata, files\n",
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import asyncio\n",
        "import aiohttp\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully\")"
      ],
      "metadata": {
        "id": "h-59q6KkVG5Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba15205-f727-49af-8d47-7df52e36e45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All libraries imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1.2: Configure API Keys\n",
        "\n",
        "try:\n",
        "    DATALAB_API_KEY = userdata.get('DATALAB_API_KEY')\n",
        "    print(\"‚úÖ Datalab API key loaded\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Add DATALAB_API_KEY to Colab Secrets\")\n",
        "    DATALAB_API_KEY = None\n",
        "\n",
        "try:\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    print(\"‚úÖ Gemini API key configured\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Add GEMINI_API_KEY to Colab Secrets\")\n",
        "    GEMINI_API_KEY = None\n",
        "\n",
        "DATALAB_MARKER_ENDPOINT = \"https://www.datalab.to/api/v1/marker\"\n",
        "gemini_model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "print(\"SETUP COMPLETE - READY FOR GRADING\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lvahFGZXCW8",
        "outputId": "ad282206-f65a-415c-fcbe-2bd69b435309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Datalab API key loaded\n",
            "‚úÖ Gemini API key configured\n",
            "SETUP COMPLETE - READY FOR GRADING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Rubric Extraction"
      ],
      "metadata": {
        "id": "57R2hI6iXIWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2.1: Define Rubric Schema\n",
        "\n",
        "RUBRIC_EXTRACTION_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"description\": \"Complete grading rubric with step-wise marking breakdown\",\n",
        "    \"properties\": {\n",
        "        \"exam_metadata\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"subject\": {\"type\": \"string\", \"description\": \"Subject name\"},\n",
        "                \"grade\": {\"type\": \"string\", \"description\": \"Grade level\"},\n",
        "                \"exam_name\": {\"type\": \"string\"},\n",
        "                \"total_marks\": {\"type\": \"string\"},\n",
        "                \"total_questions\": {\"type\": \"string\"},\n",
        "                \"duration\": {\"type\": \"string\"},\n",
        "                \"instructions\": {\"type\": \"string\"}\n",
        "            }\n",
        "        },\n",
        "        \"section_info\": {\n",
        "            \"type\": \"array\",\n",
        "            \"description\": \"Section-wise metadata\",\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"section_name\": {\"type\": \"string\"},\n",
        "                    \"question_range\": {\"type\": \"string\"},\n",
        "                    \"answer_requirement\": {\"type\": \"string\"},\n",
        "                    \"marks_per_question\": {\"type\": \"string\"},\n",
        "                    \"answer_length_limit\": {\"type\": \"string\"}\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"questions\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"question_no\": {\"type\": \"string\"},\n",
        "                    \"section\": {\"type\": \"string\"},\n",
        "                    \"question_type\": {\"type\": \"string\"},\n",
        "                    \"difficulty_level\": {\"type\": \"string\"},\n",
        "                    \"question_text_plain\": {\"type\": \"string\"},\n",
        "                    \"question_math_latex\": {\"type\": \"string\"},\n",
        "                    \"figure_summary_rubric\": {\"type\": \"string\"},\n",
        "                    \"correct_answer_plain\": {\"type\": \"string\"},\n",
        "                    \"correct_answer_latex\": {\"type\": \"string\"},\n",
        "                    \"max_marks\": {\"type\": \"string\"},\n",
        "                    \"marking_scheme\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Free-text marking guide (kept for reference)\"\n",
        "                    },\n",
        "                    # NEW FIELD: step_marking for structured, concept-based grading\n",
        "                    \"step_marking\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"description\": (\n",
        "                            \"Step-wise marking rubric. Each element represents a logical concept/step. \"\n",
        "                            \"Sum of all marksplit values should equal max_marks.\"\n",
        "                        ),\n",
        "                        \"items\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"marksplit\": {\n",
        "                                    \"type\": \"number\",\n",
        "                                    \"description\": \"Marks allocated to this concept/step\"\n",
        "                                },\n",
        "                                \"step_wise_answer\": {\n",
        "                                    \"type\": \"string\",\n",
        "                                    \"description\": (\n",
        "                                        \"Concept description for this step. \"\n",
        "                                        \"This is WHAT should be understood, not the exact wording. \"\n",
        "                                        \"Different phrasings and derivations are acceptable.\"\n",
        "                                    )\n",
        "                                },\n",
        "                                \"diagram_description\": {\n",
        "                                    \"type\": \"string\",\n",
        "                                    \"description\": \"Optional: diagram/label requirement for this step\"\n",
        "                                }\n",
        "                            }\n",
        "                        }\n",
        "                    },\n",
        "                    \"keywords\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\"type\": \"string\"},\n",
        "                        \"description\": \"Key concepts to check\"\n",
        "                    },\n",
        "                    \"diagram_labeling_requirements\": {\"type\": \"string\"}\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Extended rubric schema with step_marking defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT8OzmjIXDy3",
        "outputId": "9472630e-c74c-406c-949c-468b9002d1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extended rubric schema with step_marking defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2.2: Helper Functions for Extraction\n",
        "\n",
        "def normalize_qno(qno: str) -> str:\n",
        "    \"\"\"Normalize question numbers: Q1., 1., 1) ‚Üí 1; keep letters.\"\"\"\n",
        "    if not qno:\n",
        "        return \"\"\n",
        "    q = str(qno).strip()\n",
        "    q = q.lstrip(\"Qq\").rstrip(\".\").strip()\n",
        "    return q\n",
        "\n",
        "def call_marker_with_structured_extraction(filepath, api_key, page_schema, max_retries=3):\n",
        "    \"\"\"Call Datalab Marker API with exponential backoff retry logic\"\"\"\n",
        "    print(f\"üîÑ Processing {filepath} with Structured Extraction...\")\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            with open(filepath, 'rb') as f:\n",
        "                form_data = {\n",
        "                    'file': (filepath, f, 'application/pdf'),\n",
        "                    'page_schema': (None, json.dumps(page_schema)),\n",
        "                    'output_format': (None, 'json'),\n",
        "                    'use_llm': (None, 'true'),\n",
        "                    'force_ocr': (None, 'true'),\n",
        "                }\n",
        "\n",
        "                headers = {'X-Api-Key': api_key}\n",
        "                response = requests.post(DATALAB_MARKER_ENDPOINT, files=form_data, headers=headers)\n",
        "                data = response.json()\n",
        "\n",
        "                if not data.get('success'):\n",
        "                    error_msg = data.get('error', 'Unknown error')\n",
        "                    print(f\"  ‚ö†Ô∏è Attempt {attempt+1}/{max_retries} failed: {error_msg}\")\n",
        "                    if attempt < max_retries - 1:\n",
        "                        wait_time = 2 ** attempt\n",
        "                        print(f\"  ‚è≥ Retrying in {wait_time}s...\")\n",
        "                        time.sleep(wait_time)\n",
        "                    continue\n",
        "\n",
        "                check_url = data.get('request_check_url')\n",
        "                print(f\"  üîÑ Polling for completion...\")\n",
        "\n",
        "                for i in range(150):\n",
        "                    time.sleep(2)\n",
        "                    resp = requests.get(check_url, headers=headers)\n",
        "                    result = resp.json()\n",
        "\n",
        "                    if result.get('status') == 'complete':\n",
        "                        print(f\"  ‚úÖ Complete in {(i+1)*2}s\")\n",
        "                        return result\n",
        "                    elif result.get('status') == 'error':\n",
        "                        print(f\"  ‚ùå Processing error: {result.get('error')}\")\n",
        "                        return None\n",
        "                    elif i % 15 == 0 and i > 0:\n",
        "                        print(f\"  Still processing... {i+1}/150\")\n",
        "\n",
        "                print(\"  ‚ùå Timeout\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è Exception on attempt {attempt+1}: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                wait_time = 2 ** attempt\n",
        "                print(f\"  ‚è≥ Retrying in {wait_time}s...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                print(f\"  ‚ùå All retries exhausted\")\n",
        "                return None\n",
        "\n",
        "    return None\n",
        "\n",
        "def extract_structured_json(marker_result):\n",
        "    \"\"\"Extract JSON with triple fallback parsing\"\"\"\n",
        "    if not marker_result or not marker_result.get('success'):\n",
        "        return None, None\n",
        "\n",
        "    extraction_json_str = marker_result.get('extraction_schema_json')\n",
        "\n",
        "    if not extraction_json_str:\n",
        "        print(\"‚ö†Ô∏è No extraction_schema_json in result\")\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        extracted_data = json.loads(extraction_json_str)\n",
        "        citations = marker_result.get('json')\n",
        "        return extracted_data, citations\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"  Attempting demjson3 fallback...\")\n",
        "        try:\n",
        "            extracted_data = demjson3.decode(extraction_json_str)\n",
        "            citations = marker_result.get('json')\n",
        "            return extracted_data, citations\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå demjson3 also failed: {e}\")\n",
        "            return None, None\n",
        "\n",
        "# NEW FUNCTION: Normalize step_marking to ensure consistency\n",
        "def normalize_step_marking(reference_rubric):\n",
        "    \"\"\"\n",
        "    Normalize step_marking so that sum of marksplit equals max_marks for each question.\n",
        "    This ensures numerical consistency for grading logic.\n",
        "    \"\"\"\n",
        "    if not reference_rubric:\n",
        "        return reference_rubric\n",
        "\n",
        "    for q in reference_rubric.get(\"questions\", []):\n",
        "        # Get max_marks\n",
        "        try:\n",
        "            max_marks = float(str(q.get(\"max_marks\", \"0\")))\n",
        "        except:\n",
        "            max_marks = 0.0\n",
        "\n",
        "        steps = q.get(\"step_marking\") or []\n",
        "        if not steps or max_marks <= 0:\n",
        "            continue\n",
        "\n",
        "        # Convert all marksplit to float and sum\n",
        "        total_step_marks = 0.0\n",
        "        for step in steps:\n",
        "            try:\n",
        "                ms = float(step.get(\"marksplit\", 0))\n",
        "            except:\n",
        "                ms = 0.0\n",
        "            step[\"marksplit\"] = ms\n",
        "            total_step_marks += ms\n",
        "\n",
        "        # Rescale if needed\n",
        "        if total_step_marks <= 0:\n",
        "            continue\n",
        "\n",
        "        scale = max_marks / total_step_marks\n",
        "        for step in steps:\n",
        "            step[\"marksplit\"] = round(step[\"marksplit\"] * scale, 2)\n",
        "\n",
        "        print(f\"  ‚úì Q{q.get('question_no', '?')}: step marks normalized (sum={max_marks})\")\n",
        "\n",
        "    return reference_rubric\n",
        "\n",
        "\n",
        "print(\"‚úÖ Helper functions loaded (including normalize_step_marking)\")\n",
        "\n",
        "print(\"Helper functions loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqSqzo2HXQif",
        "outputId": "f550a268-86a0-45e2-915e-3c1691a673ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Helper functions loaded (including normalize_step_marking)\n",
            "Helper functions loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2.3: Extract Rubric from Solution Paper\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 2.3: EXTRACT REFERENCE RUBRIC\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüì§ Upload SOLUTION/MARKING SCHEME PDF...\")\n",
        "solution_uploaded = files.upload()\n",
        "solution_path = list(solution_uploaded.keys())[0]\n",
        "print(f\"‚úÖ Solution paper: {solution_path}\")\n",
        "\n",
        "print(\"\\nüîÑ Extracting rubric using Structured Extraction...\")\n",
        "rubric_result = call_marker_with_structured_extraction(\n",
        "    solution_path,\n",
        "    DATALAB_API_KEY,\n",
        "    RUBRIC_EXTRACTION_SCHEMA\n",
        ")\n",
        "\n",
        "if rubric_result:\n",
        "    reference_rubric, rubric_citations = extract_structured_json(rubric_result)\n",
        "\n",
        "    if reference_rubric:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"‚úÖ REFERENCE RUBRIC EXTRACTED\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"Subject: {reference_rubric.get('exam_metadata', {}).get('subject')}\")\n",
        "        print(f\"Total Questions: {len(reference_rubric.get('questions', []))}\")\n",
        "        print(f\"Total Marks: {reference_rubric.get('exam_metadata', {}).get('total_marks')}\")\n",
        "        print(f\"Duration: {reference_rubric.get('exam_metadata', {}).get('duration')}\")\n",
        "\n",
        "        # NEW: Normalize step_marking for numerical consistency\n",
        "        print(\"\\nüîß Normalizing step_marking across questions...\")\n",
        "        reference_rubric = normalize_step_marking(reference_rubric)\n",
        "\n",
        "        # Save rubric\n",
        "        with open('reference_rubric_v3.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(reference_rubric, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"\\n‚úÖ Rubric saved to reference_rubric_v3.json\")\n",
        "\n",
        "        # Display section info\n",
        "        print(\"\\nüìã SECTION INFORMATION:\")\n",
        "        for section in reference_rubric.get('section_info', []):\n",
        "            print(f\" Section {section['section_name']}: {section['question_range']}\")\n",
        "            print(f\" Requirement: {section['answer_requirement']}\")\n",
        "            print(f\" Marks/Question: {section['marks_per_question']}\")\n",
        "            print(f\" Answer Limit: {section['answer_length_limit']}\")\n",
        "\n",
        "        # Display sample questions with NEW step_marking\n",
        "        print(\"\\nüìù SAMPLE QUESTIONS WITH STEP-MARKING:\")\n",
        "        for q in reference_rubric.get('questions', [])[:2]:\n",
        "            print(f\"\\n Q{q['question_no']} ({q['question_type']}, {q['max_marks']} marks)\")\n",
        "            print(f\"  {q['question_text_plain'][:100]}...\")\n",
        "\n",
        "            # NEW: Show step_marking instead of just marking_scheme\n",
        "            steps = q.get('step_marking', [])\n",
        "            if steps:\n",
        "                print(f\"  Step-wise Concepts ({len(steps)}):\")\n",
        "                for i, step in enumerate(steps, 1):\n",
        "                    print(f\"    {i}. [{step['marksplit']}M] {step['step_wise_answer'][:60]}...\")\n",
        "            else:\n",
        "                print(f\"  (No step_marking available)\")\n",
        "    else:\n",
        "        print(\"‚ùå Failed to extract rubric\")\n",
        "        reference_rubric = None\n",
        "else:\n",
        "    print(\"‚ùå Marker API call failed\")\n",
        "    reference_rubric = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sLtaPgzIXf1d",
        "outputId": "a943d9aa-e354-47cf-f8e3-461eda11799a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 2.3: EXTRACT REFERENCE RUBRIC\n",
            "================================================================================\n",
            "\n",
            "üì§ Upload SOLUTION/MARKING SCHEME PDF...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03a743bd-c7f9-479c-bd53-15f85d696fb4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-03a743bd-c7f9-479c-bd53-15f85d696fb4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 11 TS Maths I A Set-A-Solution_1.pdf to 11 TS Maths I A Set-A-Solution_1 (1).pdf\n",
            "‚úÖ Solution paper: 11 TS Maths I A Set-A-Solution_1 (1).pdf\n",
            "\n",
            "üîÑ Extracting rubric using Structured Extraction...\n",
            "üîÑ Processing 11 TS Maths I A Set-A-Solution_1 (1).pdf with Structured Extraction...\n",
            "  üîÑ Polling for completion...\n",
            "  Still processing... 16/150\n",
            "  Still processing... 31/150\n",
            "  Still processing... 46/150\n",
            "  Still processing... 61/150\n",
            "  Still processing... 76/150\n",
            "  Still processing... 91/150\n",
            "  ‚úÖ Complete in 194s\n",
            "\n",
            "================================================================================\n",
            "‚úÖ REFERENCE RUBRIC EXTRACTED\n",
            "================================================================================\n",
            "Subject: MATHEMATICS ‚Äì I(A)\n",
            "Total Questions: 24\n",
            "Total Marks: 75\n",
            "Duration: 3 Hours\n",
            "\n",
            "üîß Normalizing step_marking across questions...\n",
            "  ‚úì Q1: step marks normalized (sum=2.0)\n",
            "  ‚úì Q2: step marks normalized (sum=2.0)\n",
            "  ‚úì Q3: step marks normalized (sum=2.0)\n",
            "  ‚úì Q4: step marks normalized (sum=2.0)\n",
            "  ‚úì Q5: step marks normalized (sum=2.0)\n",
            "  ‚úì Q6: step marks normalized (sum=2.0)\n",
            "  ‚úì Q7: step marks normalized (sum=2.0)\n",
            "  ‚úì Q8: step marks normalized (sum=2.0)\n",
            "  ‚úì Q9: step marks normalized (sum=2.0)\n",
            "  ‚úì Q10: step marks normalized (sum=2.0)\n",
            "  ‚úì Q11: step marks normalized (sum=4.0)\n",
            "  ‚úì Q12: step marks normalized (sum=4.0)\n",
            "  ‚úì Q13: step marks normalized (sum=4.0)\n",
            "  ‚úì Q14: step marks normalized (sum=4.0)\n",
            "  ‚úì Q15: step marks normalized (sum=4.0)\n",
            "  ‚úì Q16: step marks normalized (sum=4.0)\n",
            "  ‚úì Q17: step marks normalized (sum=4.0)\n",
            "  ‚úì Q18: step marks normalized (sum=7.0)\n",
            "  ‚úì Q19: step marks normalized (sum=7.0)\n",
            "  ‚úì Q20: step marks normalized (sum=7.0)\n",
            "  ‚úì Q21: step marks normalized (sum=7.0)\n",
            "  ‚úì Q22: step marks normalized (sum=7.0)\n",
            "  ‚úì Q23: step marks normalized (sum=7.0)\n",
            "  ‚úì Q24: step marks normalized (sum=7.0)\n",
            "\n",
            "‚úÖ Rubric saved to reference_rubric_v3.json\n",
            "\n",
            "üìã SECTION INFORMATION:\n",
            " Section SECTION ‚Äì A: 1 to 10\n",
            " Requirement: Answer ALL the questions\n",
            " Marks/Question: TWO marks\n",
            " Answer Limit: 5 lines\n",
            " Section SECTION ‚Äì B: 11 to 17\n",
            " Requirement: Answer ANY FIVE questions out of seven\n",
            " Marks/Question: FOUR marks\n",
            " Answer Limit: 20 lines\n",
            " Section SECTION ‚Äì C: 18 to 24\n",
            " Requirement: Answer ANY FIVE questions out of seven\n",
            " Marks/Question: SEVEN marks\n",
            " Answer Limit: 60 lines\n",
            "\n",
            "üìù SAMPLE QUESTIONS WITH STEP-MARKING:\n",
            "\n",
            " Q1 (Very Short Answer Type, 2 marks)\n",
            "  If f : R -> R, g: R -> R are defined by f(x) = 3x - 1 and g(x) = x^2 + 1, then find (fog)(2)....\n",
            "  Step-wise Concepts (2):\n",
            "    1. [1.0M] Finding the composite function expression (fog)(x) = 3x^2 + ...\n",
            "    2. [1.0M] Substituting x=2 to find the final value 14...\n",
            "\n",
            " Q2 (Very Short Answer Type, 2 marks)\n",
            "  Find the period of f(x) = cos((4x+9)/5)....\n",
            "  Step-wise Concepts (2):\n",
            "    1. [1.0M] Identifying the coefficient 'a' and the period formula T = 2...\n",
            "    2. [1.0M] Calculating the final period value 5pi/2...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Enhanced Student Answer Extraction\n"
      ],
      "metadata": {
        "id": "rlGQpoKDXs4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3.1: Define Enhanced Student Schema\n",
        "\n",
        "STUDENT_EXTRACTION_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"description\": \"Student exam answers with complete math, figure, and metadata support\",\n",
        "    \"properties\": {\n",
        "        \"student_metadata\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"student_name\": {\"type\": \"string\"},\n",
        "                \"roll_number\": {\"type\": \"string\"},\n",
        "                \"class_section\": {\"type\": \"string\"},\n",
        "                \"exam_date\": {\"type\": \"string\"}\n",
        "            }\n",
        "        },\n",
        "        \"answers\": {\n",
        "            \"type\": \"array\",\n",
        "            \"description\": \"Complete student answers with text & math (exclude crossed-out work)\",\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"question_no\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Normalized question number\"\n",
        "                    },\n",
        "                    \"page_number\": {\"type\": \"string\", \"description\": \"Page where answer appears\"},\n",
        "                    \"answer_sequence_position\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Position in student's writing order (1st, 2nd, 3rd answer)\"\n",
        "                    },\n",
        "                    \"section_group\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Detected section grouping (A, B, C, D)\"\n",
        "                    },\n",
        "                    \"answer_text_plain\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\":(\n",
        "                            \"Student answer as plain text and all math expressions\"\n",
        "                            \"Verbatim OCR of the FINAL answer the student intends to submit. \"\n",
        "                            \"CRITICAL: IGNORE any text that is crossed out, overwritten, \"\n",
        "                            \"or clearly cancelled. Do not include trial work that has been struck through. \"\n",
        "                            \"Include equations and mathematical expressions exactly as written.\"\n",
        "                        )\n",
        "                    },\n",
        "                    \"figure_summary_student\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Textual description of any student-drawn diagram/figure\"\n",
        "                    },\n",
        "                    \"geometry_figure_student\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"properties\": {\n",
        "                            \"points\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                            \"constructed_lines\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                            \"used_lengths\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                            \"labels_present\": {\"type\": \"array\", \"description\": \"List of labels found on diagram\"}\n",
        "                        }\n",
        "                    },\n",
        "                    \"chosen_subpart\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"For internal optional questions, which part chosen (a, b, etc.)\"\n",
        "                    },\n",
        "                    \"status\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Attempted (wrote relevant content), Blank (empty/irrelevant), Partial (incomplete work)\"\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Student schema defined with sequencing & length metadata\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZAzt5JlXj8Z",
        "outputId": "fee7ee76-852d-45f1-e5d8-067a79c0757c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student schema defined with sequencing & length metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3.2: Process Student Answers with Sequencing\n",
        "\n",
        "def process_single_student_structured(filepath, api_key, reference_rubric):\n",
        "    \"\"\"Process single student with enhanced extraction including sequencing metadata\"\"\"\n",
        "    print(f\"üìù Processing {filepath}...\")\n",
        "\n",
        "    if not reference_rubric:\n",
        "        print(\"‚ùå Reference rubric required\")\n",
        "        return None\n",
        "\n",
        "    student_result = call_marker_with_structured_extraction(\n",
        "        filepath,\n",
        "        api_key,\n",
        "        STUDENT_EXTRACTION_SCHEMA\n",
        "    )\n",
        "\n",
        "    if not student_result:\n",
        "        print(f\"‚ùå Failed to extract from {filepath}\")\n",
        "        return None\n",
        "\n",
        "    student_data, student_citations = extract_structured_json(student_result)\n",
        "\n",
        "    if student_data:\n",
        "        # Normalize question numbers and add missing blank answers\n",
        "        existing_qnos_raw = [a.get('question_no') for a in student_data.get('answers', [])]\n",
        "        existing_qnos_norm = {normalize_qno(qno) for qno in existing_qnos_raw}\n",
        "\n",
        "        for q in reference_rubric.get('questions', []):\n",
        "            qno_raw = q.get('question_no')\n",
        "            qno_norm = normalize_qno(qno_raw)\n",
        "            if qno_norm not in existing_qnos_norm:\n",
        "                student_data['answers'].append({\n",
        "                    'question_no': qno_raw,\n",
        "                    'answer_text_plain': '',\n",
        "                    'status': 'Blank'\n",
        "                })\n",
        "                existing_qnos_norm.add(qno_norm)\n",
        "\n",
        "        student_name = student_data.get('student_metadata', {}).get('student_name', 'Unknown')\n",
        "        print(f\"‚úÖ Extracted {student_name}\")\n",
        "        print(f\"   Answers: {len(student_data.get('answers', []))}\")\n",
        "\n",
        "        student_data['filename'] = filepath\n",
        "        student_data['citations'] = student_citations\n",
        "        return student_data\n",
        "    else:\n",
        "        print(f\"‚ùå JSON extraction failed\")\n",
        "        return None\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 3.2: PROCESS STUDENT EXAMS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüì§ Upload STUDENT EXAM PDFs (can upload multiple)...\")\n",
        "student_uploaded = files.upload()\n",
        "student_files = list(student_uploaded.keys())\n",
        "print(f\"‚úÖ {len(student_files)} student exams uploaded\")\n",
        "\n",
        "all_student_data = []\n",
        "if reference_rubric:\n",
        "    for student_file in student_files:\n",
        "        student_data = process_single_student_structured(\n",
        "            student_file,\n",
        "            DATALAB_API_KEY,\n",
        "            reference_rubric\n",
        "        )\n",
        "        if student_data:\n",
        "            all_student_data.append(student_data)\n",
        "\n",
        "    print(f\"\\n‚úÖ Successfully processed {len(all_student_data)}/{len(student_files)} students\")\n",
        "\n",
        "    # Save extracted student data\n",
        "    with open('all_student_answers_v3.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_student_data, f, indent=2, ensure_ascii=False)\n",
        "    print(\"‚úÖ Saved to all_student_answers_v3.json\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot process students without reference rubric\")\n",
        "    all_student_data = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jOUST7grXvOL",
        "outputId": "3ca4128d-de2f-449b-8026-ef41e65b8a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 3.2: PROCESS STUDENT EXAMS\n",
            "================================================================================\n",
            "\n",
            "üì§ Upload STUDENT EXAM PDFs (can upload multiple)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-78d3b775-bd3e-47e4-8911-e3a6e47dc661\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-78d3b775-bd3e-47e4-8911-e3a6e47dc661\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1.pdf to 1.pdf\n",
            "Saving 3.pdf to 3 (2).pdf\n",
            "Saving 4.pdf to 4 (1).pdf\n",
            "Saving 5.pdf to 5.pdf\n",
            "Saving 6.pdf to 6.pdf\n",
            "Saving 7.pdf to 7.pdf\n",
            "‚úÖ 6 student exams uploaded\n",
            "üìù Processing 1.pdf...\n",
            "üîÑ Processing 1.pdf with Structured Extraction...\n",
            "  üîÑ Polling for completion...\n",
            "  Still processing... 16/150\n",
            "  Still processing... 31/150\n",
            "  Still processing... 46/150\n",
            "  ‚úÖ Complete in 112s\n",
            "‚úÖ Extracted Thanmayee\n",
            "   Answers: 24\n",
            "üìù Processing 3 (2).pdf...\n",
            "üîÑ Processing 3 (2).pdf with Structured Extraction...\n",
            "  üîÑ Polling for completion...\n",
            "  Still processing... 16/150\n",
            "  Still processing... 31/150\n",
            "  Still processing... 46/150\n",
            "  Still processing... 61/150\n",
            "  ‚úÖ Complete in 140s\n",
            "‚úÖ Extracted Anwesh Nayak\n",
            "   Answers: 24\n",
            "üìù Processing 4 (1).pdf...\n",
            "üîÑ Processing 4 (1).pdf with Structured Extraction...\n",
            "  üîÑ Polling for completion...\n",
            "  Still processing... 16/150\n",
            "  Still processing... 31/150\n",
            "  ‚úÖ Complete in 88s\n",
            "‚úÖ Extracted Shannukha Priya V\n",
            "   Answers: 25\n",
            "üìù Processing 5.pdf...\n",
            "üîÑ Processing 5.pdf with Structured Extraction...\n",
            "  üîÑ Polling for completion...\n",
            "  Still processing... 16/150\n",
            "  Still processing... 31/150\n",
            "  Still processing... 46/150\n",
            "  ‚úÖ Complete in 104s\n",
            "‚úÖ Extracted Nikhila Sasi Sai tulasi\n",
            "   Answers: 25\n",
            "üìù Processing 6.pdf...\n",
            "üîÑ Processing 6.pdf with Structured Extraction...\n",
            "  üîÑ Polling for completion...\n",
            "  Still processing... 16/150\n",
            "  Still processing... 31/150\n",
            "  Still processing... 46/150\n",
            "  Still processing... 61/150\n",
            "  ‚úÖ Complete in 138s\n",
            "‚úÖ Extracted V. Bethu Madhav\n",
            "   Answers: 24\n",
            "üìù Processing 7.pdf...\n",
            "üîÑ Processing 7.pdf with Structured Extraction...\n",
            "  üîÑ Polling for completion...\n",
            "  Still processing... 16/150\n",
            "  Still processing... 31/150\n",
            "  Still processing... 46/150\n",
            "  Still processing... 61/150\n",
            "  ‚úÖ Complete in 132s\n",
            "‚úÖ Extracted K. Sri Vedha Kruthi\n",
            "   Answers: 24\n",
            "\n",
            "‚úÖ Successfully processed 6/6 students\n",
            "‚úÖ Saved to all_student_answers_v3.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Enhanced Constraint Validation"
      ],
      "metadata": {
        "id": "7Uz_Eaz2X3RD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5: Enhanced LLM Evaluation with Stepwise Feedback"
      ],
      "metadata": {
        "id": "rYqynnPeYKpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 5.1: Robust Gemini Call with Retries\n",
        "\n",
        "def safe_get_string(obj, key, default=\"\"):\n",
        "    \"\"\"Safely get string/list from dict - handles ALL NoneType cases\"\"\"\n",
        "    if not obj:\n",
        "        return default\n",
        "    value = obj.get(key, default)\n",
        "    if value is None:\n",
        "        return default\n",
        "    if isinstance(value, (str, list)):\n",
        "        return value\n",
        "    return str(value)\n",
        "\n",
        "def extract_json_robust(text):\n",
        "    \"\"\"Extract JSON from Gemini response with multiple extraction methods\"\"\"\n",
        "    text = text.strip()\n",
        "\n",
        "    # Method 1: ```json blocks\n",
        "    json_match = re.search(r'```json?\\s*\\n(.*?)\\n```', text, re.DOTALL)\n",
        "    if json_match:\n",
        "        return json_match.group(1).strip()\n",
        "\n",
        "    # Method 2: Largest balanced JSON\n",
        "    json_match = re.search(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', text, re.DOTALL)\n",
        "    if json_match:\n",
        "        return json_match.group(0)\n",
        "\n",
        "    # Method 3: First { to last }\n",
        "    start = text.find('{')\n",
        "    end = text.rfind('}')\n",
        "    if start != -1 and end > start:\n",
        "        return text[start:end+1]\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def parse_json_fallbacks(json_str):\n",
        "    \"\"\"Triple fallback parsing: json ‚Üí demjson3 ‚Üí None\"\"\"\n",
        "    json_str = re.sub(r'\\\\n|\\\\t', ' ', json_str)\n",
        "    json_str = re.sub(r'\\s+', ' ', json_str).strip()\n",
        "\n",
        "    try:\n",
        "        return json.loads(json_str)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        return demjson3.decode(json_str)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return None\n",
        "\n",
        "def call_gemini_with_retries(eval_prompt, question_ref, max_retries=3, base_delay=2):\n",
        "    \"\"\"\n",
        "    Production-ready LLM call with:\n",
        "    - INCREASED max_output_tokens=1024 (was 512) to reduce truncation\n",
        "    - Exponential backoff retries\n",
        "    - 429-aware heavier backoff for rate limits\n",
        "    - Structured error handling\n",
        "    \"\"\"\n",
        "    last_err = None\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = gemini_model.generate_content(\n",
        "                eval_prompt,\n",
        "                generation_config=genai.GenerationConfig(\n",
        "                    temperature=0.05, # Low temp = deterministic, less verbose\n",
        "                    max_output_tokens=1024 # INCREASED from 512\n",
        "                )\n",
        "            )\n",
        "\n",
        "            json_str = extract_json_robust(response.text)\n",
        "            result = parse_json_fallbacks(json_str)\n",
        "\n",
        "            if result:\n",
        "                return result\n",
        "\n",
        "        except Exception as e:\n",
        "            last_err = str(e)\n",
        "            err_type = type(e).__name__\n",
        "            print(f\"    ‚ö†Ô∏è Attempt {attempt+1}/{max_retries}: {err_type}\")\n",
        "\n",
        "            # Detect 429 / rate-limit and apply heavier backoff\n",
        "            if \"429\" in last_err or \"rate limit\" in last_err.lower():\n",
        "                delay = base_delay * (2 ** attempt) * 2  # Double backoff for rate limits\n",
        "                print(f\"    ‚ö†Ô∏è Rate limit (429) detected - applying extra backoff\")\n",
        "            else:\n",
        "                delay = base_delay * (2 ** attempt)\n",
        "\n",
        "            if attempt < max_retries - 1:\n",
        "                print(f\"    ‚è≥ Retrying in {delay}s...\")\n",
        "                time.sleep(delay)\n",
        "\n",
        "            if attempt < max_retries - 1:\n",
        "                delay = base_delay * (2 ** attempt)\n",
        "                print(f\"    ‚è≥ Retrying in {delay}s...\")\n",
        "                time.sleep(delay)\n",
        "\n",
        "    return {\n",
        "        \"question_no\": safe_get_string(question_ref, \"question_no\"),\n",
        "        \"marks_awarded\": \"ERROR\",\n",
        "        \"max_marks\": safe_get_string(question_ref, \"max_marks\"),\n",
        "        \"feedback\": f\"Failed after {max_retries} retries\",\n",
        "        \"status\": \"Error\"\n",
        "    }\n",
        "\n",
        "print(\"Robust Gemini call with retries ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5viNIZp3YE8E",
        "outputId": "d8b219ef-845c-4475-b9e0-70e9ced2abd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Robust Gemini call with retries ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 5.2: Enhanced Evaluation with Stepwise Feedback\n",
        "\n",
        "def evaluate_single_answer_robust(question_ref, student_answer_text, student_status,\n",
        "                                  student_figures=\"\",\n",
        "                                  section_meta=None):\n",
        "    \"\"\"\n",
        "    Build a comprehensive grading prompt that:\n",
        "    1. Treats rubric step_marking as a SET of concepts (not ordered sequence)\n",
        "    2. Encourages liberal, concept-based scoring\n",
        "    3. Accepts equivalent derivations and alternative phrasings\n",
        "    4. Returns compact, structured JSON output\n",
        "    \"\"\"\n",
        "\n",
        "    # FIXED BLANK CHECK - Check ACTUAL CONTENT, not status\n",
        "    fig_clean = (student_figures or \"\").strip()\n",
        "\n",
        "    # If ALL content fields are truly empty ‚Üí NO LLM CALL\n",
        "    if not (student_answer_text or \"\").strip() and not fig_clean:\n",
        "        return {\n",
        "            \"question_no\": safe_get_string(question_ref, \"question_no\"),\n",
        "            \"marks_awarded\": \"0\",\n",
        "            \"max_marks\": safe_get_string(question_ref, \"max_marks\", \"0\"),\n",
        "            \"feedback\": \"Answer not attempted\",\n",
        "            \"stepwise_feedback\": [],\n",
        "            \"diagram_feedback\": \"N/A\",\n",
        "            \"status\": \"Blank\"\n",
        "        }\n",
        "\n",
        "    # SAFE RUBRIC GEOMETRY\n",
        "    # Ensure rubric_geometry is always a dictionary\n",
        "    rubric_geometry = question_ref.get(\"geometry_figure_rubric\", {})\n",
        "    # If it happens to be a string (e.g., from an imperfect extraction), try to parse it\n",
        "    if isinstance(rubric_geometry, str):\n",
        "        try:\n",
        "            rubric_geometry = json.loads(rubric_geometry)\n",
        "        except json.JSONDecodeError:\n",
        "            rubric_geometry = {} # Fallback to empty dict if parsing fails\n",
        "\n",
        "    rubric_figure_summary = safe_get_string(question_ref, \"figure_summary_rubric\", \"\")\n",
        "\n",
        "    # ENHANCED PROMPT WITH STEPWISE FEEDBACK REQUEST\n",
        "    eval_prompt = f\"\"\"You are an STEM subject expert examiner grading subjective & objective student answer for questions using detailed rubric.\n",
        "\n",
        "==QUESTION DETAILS==\n",
        "Question No: {safe_get_string(question_ref, 'question_no')}\n",
        "Section: {safe_get_string(question_ref, 'section', 'Unknown')}\n",
        "Question Type: {safe_get_string(question_ref, 'question_type')}\n",
        "Question Text: {safe_get_string(question_ref, 'question_text_plain')}\n",
        "\n",
        "==RUBRIC REQUIREMENTS==\n",
        "Max Marks: {safe_get_string(question_ref, 'max_marks', '5')}\n",
        "Marking Scheme (STEPWISE):\n",
        "{safe_get_string(question_ref, 'marking_scheme', 'Grade on correctness, completeness, and reasoning')}\n",
        "\n",
        "Keywords to Check: {', '.join(safe_get_string(question_ref, 'keywords', []))}\n",
        "\n",
        "==DIAGRAM REQUIREMENTS (if applicable)==\n",
        "{safe_get_string(question_ref, 'diagram_labeling_requirements', 'N/A')}\n",
        "\n",
        "Rubric Geometry:\n",
        "- Points: {safe_get_string(rubric_geometry, 'points', [])}\n",
        "- Constructions: {safe_get_string(rubric_geometry, 'construction_rules', 'N/A')}\n",
        "\n",
        "==REFERENCE SOLUTION==\n",
        "Plain Text Answer:\n",
        "{safe_get_string(question_ref, 'correct_answer_plain')}\n",
        "\n",
        "==STUDENT'S ANSWER==\n",
        "Plain Text:\n",
        "{student_answer_text}\n",
        "\n",
        "Diagrams/Figures:\n",
        "{student_figures}\n",
        "\n",
        "==EVALUATION REQUIREMENTS==\n",
        "1. TREAT RUBRIC STEPS AS A SET OF CONCEPTS, NOT A RIGID SEQUENCE\n",
        "   - Order does NOT matter\n",
        "   - A student can address concepts in any sequence\n",
        "\n",
        "2. SCAN FOR EACH CONCEPT ANYWHERE IN THE ANSWER\n",
        "   - Look for the IDEA, not exact wording\n",
        "   - Accept rephrasing, alternative notations, different variable names\n",
        "\n",
        "3. AWARD MARKS FOR CONCEPTUAL CORRECTNESS\n",
        "   - If the reasoning is mathematically/physically correct, award marks\n",
        "   - Even if the student uses a different derivation or approach\n",
        "   - Accept algebraically equivalent equations and expressions\n",
        "\n",
        "4. BE LIBERAL WITH PARTIAL CREDIT\n",
        "   - Award marks if the concept is clearly demonstrated\n",
        "   - Partial marks if the idea is present but incomplete/imprecise\n",
        "   - Zero only if the concept is clearly absent or incorrect\n",
        "\n",
        "5. EXAMPLE SCENARIOS TO SCORE GENEROUSLY:\n",
        "   - Student uses alternative (equivalent) formula ‚Üí Full marks\n",
        "   - Student combines multiple steps into one line ‚Üí Full marks if correct\n",
        "   - Student writes concept in different order ‚Üí Full marks\n",
        "   - Student uses different symbols (x instead of Œ∏, etc.) ‚Üí Full marks if meaning is clear\n",
        "\n",
        "==OUTPUT FORMAT==\n",
        "Provide evaluation in this EXACT JSON format:\n",
        "{{\n",
        "  \"question_no\": \"{safe_get_string(question_ref, 'question_no')}\",\n",
        "  \"marks_awarded\": 3.5,\n",
        "  \"max_marks\": \"{safe_get_string(question_ref, 'max_marks')}\",\n",
        "  \"stepwise_feedback\": [\n",
        "    {{\n",
        "      \"step_id\": 1,\n",
        "      \"description\": \"<rubric concept from above>\",\n",
        "      \"marks_awarded\": <number between 0 and max_marks for this step>,\n",
        "      \"max_marks\": <from rubric>,\n",
        "      \"feedback\": \"<one short sentence. Examples: 'Correct', 'Missing derivation', 'Partially correct because...', 'Not shown'>\"\n",
        "    }},\n",
        "    {{\n",
        "      \"step_id\": 2,\n",
        "      \"description\": \"<next rubric concept>\",\n",
        "      \"marks_awarded\": <number>,\n",
        "      \"max_marks\": <from rubric>,\n",
        "      \"feedback\": \"<one short sentence>\"\n",
        "    }}\n",
        "    ... (one entry per step_marking item)\n",
        " ],\n",
        "  \"diagram_feedback\": \"Labels present: Point A, B, C. Missing: angle measurements. Overall clarity: Good\",\n",
        "  \"keyword_check\": {{\"keyword\": \"Lorentz force\", \"present\": true}},\n",
        "  \"overall_feedback\": \"<2‚Äì4 short sentences summarizing answer quality>\",\n",
        "  \"status\": \"Attempted\"\n",
        "}}\"\"\"\n",
        "\n",
        "    return call_gemini_with_retries(eval_prompt, question_ref, max_retries=3, base_delay=2)\n",
        "\n",
        "def postprocess_evaluation(eval_result, max_marks):\n",
        "    \"\"\"Post-process for consistent status\"\"\"\n",
        "    if not eval_result:\n",
        "        return {\"status\": \"Error\"}\n",
        "\n",
        "    marks_str = str(eval_result.get(\"marks_awarded\", \"0\")).strip()\n",
        "    if marks_str == \"ERROR\":\n",
        "        return eval_result\n",
        "\n",
        "    try:\n",
        "        marks = float(marks_str)\n",
        "        max_m = float(max_marks or 0)\n",
        "        if marks >= max_m * 0.9:\n",
        "            eval_result[\"status\"] = \"Correct\"\n",
        "        elif marks > 0:\n",
        "            eval_result[\"status\"] = \"Attempted\"\n",
        "        else:\n",
        "            eval_result[\"status\"] = \"Blank\"\n",
        "    except (ValueError, TypeError):\n",
        "        eval_result[\"status\"] = \"Error\"\n",
        "\n",
        "    return eval_result\n",
        "\n",
        "print(\"Enhanced evaluation with stepwise feedback ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXkYBsyQYMwM",
        "outputId": "7a9c311d-3710-49a1-a112-a8097bc01ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced evaluation with stepwise feedback ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6: Batch Evaluation with All Enhancements"
      ],
      "metadata": {
        "id": "ZpDL-UkJYaxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 6.1: Complete Batch Evaluation Pipeline\n",
        "\n",
        "def evaluate_all_students_enhanced(reference_rubric, all_student_data, delay=0.5):\n",
        "    \"\"\"Batch evaluation with ALL enhancements: constraints, lengths, sequencing, feedback\"\"\"\n",
        "    all_evaluations = []\n",
        "    rubric_questions = reference_rubric.get('questions', []) or []\n",
        "    section_info = {s['section_name']: s for s in reference_rubric.get('section_info', [])}\n",
        "    total_students = len(all_student_data)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"PART 6: EVALUATING {total_students} STUDENTS WITH ALL ENHANCEMENTS\")\n",
        "\n",
        "    for student_idx, student_data in enumerate(all_student_data, 1):\n",
        "        student_name = safe_get_string(student_data.get('student_metadata', {}), 'student_name')\n",
        "        student_roll = safe_get_string(student_data.get('student_metadata', {}), 'roll_number')\n",
        "\n",
        "        print(f\"\\n[{student_idx}/{total_students}] {student_name} (Roll: {student_roll})\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        student_evaluations = []\n",
        "        student_answers = student_data.get('answers', []) or []\n",
        "\n",
        "        # Build answer lookup\n",
        "        answer_dict = {}\n",
        "        for a in student_answers:\n",
        "            qno_raw = a.get('question_no')\n",
        "            qno_norm = normalize_qno(qno_raw)\n",
        "\n",
        "            if not qno_norm:\n",
        "                continue\n",
        "\n",
        "            # Only append once per key\n",
        "            if qno_norm not in answer_dict:\n",
        "              answer_dict[qno_norm] = []\n",
        "            answer_dict[qno_norm].append(a)\n",
        "            # answer_dict.setdefault(qno_norm, []).append(a)\n",
        "\n",
        "            m = re.match(r\"(\\d+)\", qno_norm)\n",
        "            if m:\n",
        "                base = m.group(1)\n",
        "                if base != qno_norm:  # prevent duplicates when base == qno_norm\n",
        "                    answer_dict.setdefault(base, []).append(a)\n",
        "\n",
        "        # Evaluate each question\n",
        "        for q_ref in rubric_questions:\n",
        "            qno_raw = q_ref.get('question_no')\n",
        "            qno_norm = normalize_qno(qno_raw)\n",
        "            section = q_ref.get('section', 'Unknown')\n",
        "            section_meta = section_info.get(section, {})\n",
        "\n",
        "            print(f\"  Q{qno_raw}...\", end=\" \", flush=True)\n",
        "\n",
        "            all_segments = answer_dict.get(qno_norm, [])\n",
        "            answer_segments = [seg for seg in all_segments\n",
        "                             if safe_get_string(seg, \"answer_text_plain\")]\n",
        "\n",
        "            if answer_segments:\n",
        "                answer_text = \" \".join(safe_get_string(seg, \"answer_text_plain\") for seg in answer_segments).strip()\n",
        "                answer_figures = \" \".join(safe_get_string(seg, \"figure_summary_student\") for seg in answer_segments\n",
        "                                         if safe_get_string(seg, \"figure_summary_student\")).strip()\n",
        "                status = safe_get_string(answer_segments[0], \"status\", \"Attempted\")\n",
        "            else:\n",
        "                answer_text = \"\"\n",
        "                answer_figures = \"\"\n",
        "                status = \"Blank\"\n",
        "\n",
        "            # Evaluate with LLM\n",
        "            eval_result = evaluate_single_answer_robust(\n",
        "                q_ref, answer_text, status, answer_figures, section_meta\n",
        "            )\n",
        "\n",
        "            eval_result = postprocess_evaluation(eval_result, q_ref.get('max_marks', '0'))\n",
        "\n",
        "            if eval_result:\n",
        "                eval_result['question_type'] = q_ref.get('question_type')\n",
        "                eval_result['question_text'] = q_ref.get('question_text_plain')\n",
        "                eval_result['student_answer_plain'] = answer_text\n",
        "                eval_result['student_figures'] = answer_figures\n",
        "                # eval_result['length_violations'] = length_violations\n",
        "                eval_result['section'] = section\n",
        "\n",
        "                student_evaluations.append(eval_result)\n",
        "\n",
        "                marks = eval_result.get('marks_awarded', 'N/A')\n",
        "                print(f\"‚úì {marks}/{eval_result.get('max_marks')} [{eval_result.get('status')}]\")\n",
        "            else:\n",
        "                print(\"‚úó Failed\")\n",
        "\n",
        "            time.sleep(delay)\n",
        "\n",
        "        # Calculate totals\n",
        "        total_awarded = 0\n",
        "        total_max = 0\n",
        "        for ev in student_evaluations:\n",
        "            try:\n",
        "                if ev.get(\"marks_awarded\") != \"ERROR\":\n",
        "                    total_awarded += float(ev.get(\"marks_awarded\", 0))\n",
        "                total_max += float(ev.get(\"max_marks\", 0))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        percentage = round((total_awarded / total_max * 100) if total_max else 0, 1)\n",
        "        print(f\"\\n  üìä TOTAL: {total_awarded:.1f}/{total_max:.1f} ({percentage}%)\")\n",
        "\n",
        "        # if section_violations:\n",
        "        #     print(f\"  ‚ö†Ô∏è Section violations penalty applied\")\n",
        "\n",
        "        all_evaluations.append({\n",
        "            'student_metadata': student_data.get('student_metadata'),\n",
        "            'filename': student_data.get('filename', 'unknown'),\n",
        "            'evaluations': student_evaluations,\n",
        "            # 'section_constraint_violations': section_violations,\n",
        "            # 'sequence_issues': sequence_issues,\n",
        "            'total_marks_awarded': round(total_awarded, 1),\n",
        "            'total_max_marks': round(total_max, 1),\n",
        "            'percentage': percentage\n",
        "        })\n",
        "\n",
        "    return all_evaluations\n",
        "\n",
        "# RUN EVALUATION\n",
        "if reference_rubric and all_student_data:\n",
        "    all_evaluations = evaluate_all_students_enhanced(reference_rubric, all_student_data, delay=0.3)\n",
        "\n",
        "    with open('all_evaluations_v3_complete.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_evaluations, f, indent=2, ensure_ascii=False)\n",
        "    print(\"\\n‚úÖ Complete evaluations saved to all_evaluations_v3_complete.json\")\n",
        "else:\n",
        "    print(\"‚ùå Missing rubric or student data\")\n",
        "    all_evaluations = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2a76ia8TYUpX",
        "outputId": "e50caf34-cc4e-477d-b8d8-d7d1034f20bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PART 6: EVALUATING 6 STUDENTS WITH ALL ENHANCEMENTS\n",
            "\n",
            "[1/6] Thanmayee (Roll: 83111007)\n",
            "--------------------------------------------------------------------------------\n",
            "  Q1... ‚úì 2.0/2 [Correct]\n",
            "  Q2... ‚úì 2.0/2 [Correct]\n",
            "  Q3... ‚úì 2.0/2 [Correct]\n",
            "  Q4... ‚úì 2.0/2 [Correct]\n",
            "  Q5... ‚úì 2.0/2 [Correct]\n",
            "  Q6... ‚úì 1.0/2 [Attempted]\n",
            "  Q7... ‚úì 2.0/2 [Correct]\n",
            "  Q8... ‚úì 2.0/2 [Correct]\n",
            "  Q9... ‚úì 2.0/2 [Correct]\n",
            "  Q10... ‚úì 2.0/2 [Correct]\n",
            "  Q11... ‚úì 3.5/4 [Attempted]\n",
            "  Q12... ‚úì 3.5/4 [Attempted]\n",
            "  Q13... ‚úì 0/4 [Blank]\n",
            "  Q14... ‚úì 3.5/4 [Attempted]\n",
            "  Q15... ‚úì 3.5/4 [Attempted]\n",
            "  Q16... ‚úì 3.5/4 [Attempted]\n",
            "  Q17... ‚úì 0/4 [Blank]\n",
            "  Q18... ‚úì 3.5/7 [Attempted]\n",
            "  Q19... ‚úì 3.5/7 [Attempted]\n",
            "  Q20... ‚úì 7.0/7 [Correct]\n",
            "  Q21... ‚úì 7.0/7 [Correct]\n",
            "  Q22... ‚úì 0/7 [Blank]\n",
            "  Q23... ‚úì 3.5/7 [Attempted]\n",
            "  Q24... ‚úì 0/7 [Blank]\n",
            "\n",
            "  üìä TOTAL: 61.0/97.0 (62.9%)\n",
            "\n",
            "[2/6] Anwesh Nayak (Roll: 8311064)\n",
            "--------------------------------------------------------------------------------\n",
            "  Q1... ‚úì 2.0/2 [Correct]\n",
            "  Q2... ‚úì 2.0/2 [Correct]\n",
            "  Q3... ‚úì 0/2 [Blank]\n",
            "  Q4... ‚úì 2.0/2 [Correct]\n",
            "  Q5... ‚úì 2.0/2 [Correct]\n",
            "  Q6... ‚úì 1.5/2 [Attempted]\n",
            "  Q7... ‚úì 2.0/2 [Correct]\n",
            "  Q8... ‚úì 2.0/2 [Correct]\n",
            "  Q9... ‚úì 2.0/2 [Correct]\n",
            "  Q10... ‚úì 0.0/2 [Blank]\n",
            "  Q11... ‚úì 0.0/4 [Blank]\n",
            "  Q12... ‚úì 0.0/4 [Blank]\n",
            "  Q13... ‚úì 0.0/4 [Blank]\n",
            "  Q14... ‚úì 3.5/4 [Attempted]\n",
            "  Q15... ‚úì 0/4 [Blank]\n",
            "  Q16... ‚úì 3.5/4 [Attempted]\n",
            "  Q17... ‚úì 0/4 [Blank]\n",
            "  Q18... ‚úì 0.0/7 [Blank]\n",
            "  Q19... ‚úì 0/7 [Blank]\n",
            "  Q20... ‚úì 3.5/7 [Attempted]\n",
            "  Q21... ‚úì 0.0/7 [Blank]\n",
            "  Q22... ‚úì 0/7 [Blank]\n",
            "  Q23... ‚úì 0.0/7 [Blank]\n",
            "  Q24... ‚úì 3.5/7 [Attempted]\n",
            "\n",
            "  üìä TOTAL: 29.5/97.0 (30.4%)\n",
            "\n",
            "[3/6] Shannukha Priya V (Roll: 83111339)\n",
            "--------------------------------------------------------------------------------\n",
            "  Q1... ‚úì 2.0/2 [Correct]\n",
            "  Q2... ‚úì 2.0/2 [Correct]\n",
            "  Q3... ‚úì 2/2 [Correct]\n",
            "  Q4... ‚úì 2.0/2 [Correct]\n",
            "  Q5... ‚úì 2.0/2 [Correct]\n",
            "  Q6... ‚úì 0.0/2 [Blank]\n",
            "  Q7... ‚úì 1.5/2 [Attempted]\n",
            "  Q8... ‚úì 2.0/2 [Correct]\n",
            "  Q9... ‚úì 2.0/2 [Correct]\n",
            "  Q10... ‚úì 2.0/2 [Correct]\n",
            "  Q11... ‚úì 3.5/4 [Attempted]\n",
            "  Q12... ‚úì 3.5/4 [Attempted]\n",
            "  Q13... ‚úì 0/4 [Blank]\n",
            "  Q14... ‚úì 3.5/4 [Attempted]\n",
            "  Q15... ‚úì 3.5/4 [Attempted]\n",
            "  Q16... ‚úì 3.5/4 [Attempted]\n",
            "  Q17... ‚úì 0/4 [Blank]\n",
            "  Q18... ‚úì 7.0/7 [Correct]\n",
            "  Q19... ‚úì 0/7 [Blank]\n",
            "  Q20... ‚úì 0/7 [Blank]\n",
            "  Q21... ‚úì 3.5/7 [Attempted]\n",
            "  Q22... ‚úì 0/7 [Blank]\n",
            "  Q23... ‚úì 7.0/7 [Correct]\n",
            "  Q24... ‚úì 3.5/7 [Attempted]\n",
            "\n",
            "  üìä TOTAL: 56.0/97.0 (57.7%)\n",
            "\n",
            "[4/6] Nikhila Sasi Sai tulasi (Roll: 83111300)\n",
            "--------------------------------------------------------------------------------\n",
            "  Q1... ‚úì 2.0/2 [Correct]\n",
            "  Q2... ‚úì 2.0/2 [Correct]\n",
            "  Q3... ‚úì 2.0/2 [Correct]\n",
            "  Q4... ‚úì 2.0/2 [Correct]\n",
            "  Q5... ‚úì 2.0/2 [Correct]\n",
            "  Q6... ‚úì 1.75/2 [Attempted]\n",
            "  Q7... ‚úì 2/2 [Correct]\n",
            "  Q8... ‚úì 2.0/2 [Correct]\n",
            "  Q9... ‚úì 2.0/2 [Correct]\n",
            "  Q10... ‚úì 2.0/2 [Correct]\n",
            "  Q11... ‚úì 3.5/4 [Attempted]\n",
            "  Q12... ‚úì 3.5/4 [Attempted]\n",
            "  Q13... ‚úì 3.5/4 [Attempted]\n",
            "  Q14... ‚úì 3.5/4 [Attempted]\n",
            "  Q15... ‚úì 3.5/4 [Attempted]\n",
            "  Q16... ‚úì 3.5/4 [Attempted]\n",
            "  Q17... ‚úì 0/4 [Blank]\n",
            "  Q18... ‚úì 7.0/7 [Correct]\n",
            "  Q19... ‚úì 3.5/7 [Attempted]\n",
            "  Q20... ‚úì 7.0/7 [Correct]\n",
            "  Q21... ‚úì 7.0/7 [Correct]\n",
            "  Q22... ‚úì 0/7 [Blank]\n",
            "  Q23... ‚úì 0/7 [Blank]\n",
            "  Q24... ‚úì 3.5/7 [Attempted]\n",
            "\n",
            "  üìä TOTAL: 68.8/97.0 (70.9%)\n",
            "\n",
            "[5/6] V. Bethu Madhav (Roll: 83111267)\n",
            "--------------------------------------------------------------------------------\n",
            "  Q1... ‚úì 2.0/2 [Correct]\n",
            "  Q2... ‚úì 2.0/2 [Correct]\n",
            "  Q3... ‚úì 2.0/2 [Correct]\n",
            "  Q4... ‚úì 2.0/2 [Correct]\n",
            "  Q5... ‚úì 2.0/2 [Correct]\n",
            "  Q6... ‚úì 1.5/2 [Attempted]\n",
            "  Q7... ‚úì 2.0/2 [Correct]\n",
            "  Q8... ‚úì 2.0/2 [Correct]\n",
            "  Q9... ‚úì 0.0/2 [Blank]\n",
            "  Q10... ‚úì 2.0/2 [Correct]\n",
            "  Q11... ‚úì 3.5/4 [Attempted]\n",
            "  Q12... ‚úì 3.5/4 [Attempted]\n",
            "  Q13... ‚úì 3.5/4 [Attempted]\n",
            "  Q14... ‚úì 0/4 [Blank]\n",
            "  Q15... ‚úì 3.5/4 [Attempted]\n",
            "  Q16... ‚úì 3.5/4 [Attempted]\n",
            "  Q17... ‚úì 3.5/4 [Attempted]\n",
            "  Q18... ‚úì 3.5/7 [Attempted]\n",
            "  Q19... ‚úì 3.5/7 [Attempted]\n",
            "  Q20... ‚úì 3.5/7 [Attempted]\n",
            "  Q21... ‚úì 7.0/7 [Correct]\n",
            "  Q22... ‚úì 0/7 [Blank]\n",
            "  Q23... ‚úì 0/7 [Blank]\n",
            "  Q24... ‚úì 3.5/7 [Attempted]\n",
            "\n",
            "  üìä TOTAL: 59.5/97.0 (61.3%)\n",
            "\n",
            "[6/6] K. Sri Vedha Kruthi (Roll: 8311103)\n",
            "--------------------------------------------------------------------------------\n",
            "  Q1... ‚úì 2.0/2 [Correct]\n",
            "  Q2... ‚úì 0/2 [Blank]\n",
            "  Q3... ‚úì 0/2 [Blank]\n",
            "  Q4... ‚úì 0/2 [Blank]\n",
            "  Q5... ‚úì 2.0/2 [Correct]\n",
            "  Q6... ‚úì 1.5/2 [Attempted]\n",
            "  Q7... ‚úì 0.5/2 [Attempted]\n",
            "  Q8... ‚úì 0.5/2 [Attempted]\n",
            "  Q9... ‚úì 0/2 [Blank]\n",
            "  Q10... ‚úì 1.0/2 [Attempted]\n",
            "  Q11... ‚úì 0/4 [Blank]\n",
            "  Q12... ‚úì 3.5/4 [Attempted]\n",
            "  Q13... ‚úì 0/4 [Blank]\n",
            "  Q14... ‚úì 3.5/4 [Attempted]\n",
            "  Q15... ‚úì 3.5/4 [Attempted]\n",
            "  Q16... ‚úì 3.5/4 [Attempted]\n",
            "  Q17... ‚úì 3.5/4 [Attempted]\n",
            "  Q18... ‚úì 3.5/7 [Attempted]\n",
            "  Q19... ‚úì 3.5/7 [Attempted]\n",
            "  Q20... ‚úì 3.5/7 [Attempted]\n",
            "  Q21... ‚úì 3.5/7 [Attempted]\n",
            "  Q22... ‚úì 3.5/7 [Attempted]\n",
            "  Q23... ‚úì 3.5/7 [Attempted]\n",
            "  Q24... ‚úì 0/7 [Blank]\n",
            "\n",
            "  üìä TOTAL: 46.0/97.0 (47.4%)\n",
            "\n",
            "‚úÖ Complete evaluations saved to all_evaluations_v3_complete.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 7: Enhanced CSV Export with Complete Details"
      ],
      "metadata": {
        "id": "dVmIumjaYltW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 7.1: Generate Detailed CSV Reports\n",
        "\n",
        "def export_to_enhanced_csv_v3(all_evaluations, output_filename='grading_results.csv'):\n",
        "    \"\"\"Export evaluations to CSV with COMPLETE student answers and stepwise feedback\"\"\"\n",
        "    rows = []\n",
        "\n",
        "    print(\"üîÑ Building detailed CSV with COMPLETE answers and stepwise feedback...\")\n",
        "\n",
        "    for student_eval in all_evaluations:\n",
        "        student_name = safe_get_string(student_eval.get('student_metadata', {}), 'student_name')\n",
        "        student_roll = safe_get_string(student_eval.get('student_metadata', {}), 'roll_number')\n",
        "        class_section = safe_get_string(student_eval.get('student_metadata', {}), 'class_section')\n",
        "\n",
        "        for eval_item in student_eval.get('evaluations', []):\n",
        "            # Format stepwise feedback\n",
        "            stepwise_remarks = \"\"\n",
        "            if eval_item.get('stepwise_feedback'):\n",
        "                for step in eval_item['stepwise_feedback']:\n",
        "                    step_id = step.get('step_id')\n",
        "                    desc = step.get('description') or \"\"\n",
        "                    marks = step.get('marks_awarded')\n",
        "                    max_marks = step.get('max_marks')\n",
        "                    fb = step.get('feedback') or \"\"\n",
        "\n",
        "                    # Optional: safe formatting to avoid None appearing\n",
        "                    step_label = f\"Step {step_id}\" if step_id is not None else \"Step\"\n",
        "                    marks_label = (\n",
        "                        f\"{marks}/{max_marks}\"\n",
        "                        if marks is not None and max_marks is not None\n",
        "                        else \"\"\n",
        "                    )\n",
        "\n",
        "                    stepwise_remarks += (\n",
        "                        f\"{step_label}: {desc}\"\n",
        "                        + (f\" ({marks_label} marks)\" if marks_label else \"\")\n",
        "                        + (f\" - {fb}\" if fb else \"\")\n",
        "                        + \"; \"\n",
        "                    )\n",
        "                    # stepwise_remarks += f\"Step {step.get('step')}: {step.get('description')} ({step.get('marks_for_step')} marks) - {step.get('remarks')}; \"\n",
        "\n",
        "            row = {\n",
        "                'Name': student_name,\n",
        "                'Roll No.': student_roll,\n",
        "                'Class-Section': class_section,\n",
        "                'Q.No': eval_item.get('question_no', ''),\n",
        "                'Section': eval_item.get('section', ''),\n",
        "                'Question': eval_item.get('question_text', ''),\n",
        "                'Student_Answer': eval_item.get('student_answer_plain', ''),\n",
        "                'Student_Figures': eval_item.get('student_figures', ''),\n",
        "                'Score': eval_item.get('marks_awarded', 'N/A'),\n",
        "                'Max_Marks': eval_item.get('max_marks', 'N/A'),\n",
        "                'Status': eval_item.get('status', ''),\n",
        "                'Feedback': eval_item.get('overall_feedback', ''),\n",
        "                'Stepwise_Feedback': stepwise_remarks,\n",
        "                'Diagram_Feedback': eval_item.get('diagram_feedback', ''),\n",
        "            }\n",
        "            rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Light cleanup\n",
        "    for col in ['Question', 'Student_Answer']:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"‚úÖ Exported to {output_filename}\")\n",
        "    print(f\"   üìà Rows: {len(df):,}\")\n",
        "    print(f\"   üë• Students: {df['Name'].nunique()}\")\n",
        "    print(f\"   üìè Longest answer: {df['Student_Answer'].str.len().max()} chars\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def export_summary_enhanced_v3(all_evaluations, output_filename='summary_report.csv'):\n",
        "    \"\"\"Generate summary with grades and constraint violations\"\"\"\n",
        "    rows = []\n",
        "\n",
        "    for student_eval in all_evaluations:\n",
        "        total_marks = student_eval.get('total_marks_awarded', 0)\n",
        "        total_max = student_eval.get('total_max_marks', 0)\n",
        "\n",
        "        row = {\n",
        "            'Name': safe_get_string(student_eval.get('student_metadata', {}), 'student_name'),\n",
        "            'RollNumber': safe_get_string(student_eval.get('student_metadata', {}), 'roll_number'),\n",
        "            'Class-Section': safe_get_string(student_eval.get('student_metadata', {}), 'class_section'),\n",
        "            'TotalMarksAwarded': total_marks,\n",
        "            'TotalMaxMarks': total_max,\n",
        "            'Filename': student_eval.get('filename', '')\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"‚úÖ Summary exported: {output_filename}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# GENERATE REPORTS\n",
        "if all_evaluations:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"PART 7: EXPORT COMPLETE GRADING REPORTS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    detailed_df = export_to_enhanced_csv_v3(all_evaluations, 'grading_results.csv')\n",
        "    summary_df = export_summary_enhanced_v3(all_evaluations, 'summary_report.csv')\n",
        "\n",
        "    print(\"\\nüéØ FILES GENERATED:\")\n",
        "    print(\"   ‚úÖ grading_results.csv ‚Üê Complete answers + stepwise feedback\")\n",
        "    print(\"   ‚úÖ summary_report.csv ‚Üê Grades + constraint analysis\")\n",
        "    print(\"   ‚úÖ all_evaluations.json ‚Üê Raw JSON data\")\n",
        "else:\n",
        "    print(\"‚ùå No evaluations to export\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C6DjkjLYesY",
        "outputId": "8bbda4e5-8e4a-480d-81e4-8c104bca8dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "PART 7: EXPORT COMPLETE GRADING REPORTS\n",
            "================================================================================\n",
            "üîÑ Building detailed CSV with COMPLETE answers and stepwise feedback...\n",
            "‚úÖ Exported to grading_results.csv\n",
            "   üìà Rows: 144\n",
            "   üë• Students: 6\n",
            "   üìè Longest answer: 1182 chars\n",
            "‚úÖ Summary exported: summary_report.csv\n",
            "\n",
            "üéØ FILES GENERATED:\n",
            "   ‚úÖ grading_results.csv ‚Üê Complete answers + stepwise feedback\n",
            "   ‚úÖ summary_report.csv ‚Üê Grades + constraint analysis\n",
            "   ‚úÖ all_evaluations.json ‚Üê Raw JSON data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "This **enhanced grading pipeline v3.0** provides:\n",
        "\n",
        "‚úÖ **Complete Answer Preservation** - No truncation, plain text & LaTeX separated  \n",
        "‚úÖ **Rubric Compliance Enforcement** - Section choices, answer length limits validated  \n",
        "‚úÖ **Intelligent Sequencing** - Detects and validates answer ordering  \n",
        "‚úÖ **Diagram Accuracy Checks** - Labeling requirements explicitly evaluated  \n",
        "‚úÖ **Stepwise Marking Feedback** - Students see detailed breakdown of marks per step  \n",
        "‚úÖ **Production-Ready Robustness** - Triple-fallback JSON parsing, exponential backoff retries  \n",
        "‚úÖ **Audit Trail & Compliance** - All constraint violations logged for review  \n",
        "\n",
        "**Ready for deployment in production exam grading systems!** üöÄ"
      ],
      "metadata": {
        "id": "xT4jAAGKYqcY"
      }
    }
  ]
}